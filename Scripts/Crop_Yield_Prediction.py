# -*- coding: utf-8 -*-
"""MTech_Project_30_Single_Crop_Maize_AESR_Weather.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K998pG6FWGpMqP2mHlPuMKpkNtuBJ365
"""

import keras
import pandas as pd
import numpy as np
import math
from google.colab import drive
import pickle
from sklearn.metrics import mean_squared_error, mean_absolute_error
from keras.models import Sequential
from keras.layers import Dense, Conv1D, Flatten
import tensorflow as tf
import matplotlib.pyplot as plt

data = pd.read_csv('/content/Crop_Yield_Data_Final.csv')

data.head()

data.columns

# Defining results

rmse = []
ci_95 = []
ci_90 = []
r2 = []
corr = []

i = 0

while i < len(data):
  if data.iloc[i]['Crop_Maize'] != 1:
    data.drop(data.iloc[i].name,  inplace=True)
  else:
    i+=1
  print(i)

data.drop(['Area(Hectares)', 'Production(Tonnes)','Season_Kharif', 'Season_Rabi', 'Crop_Barley', 'Crop_Maize', 'Crop_Rice', 'Crop_Wheat','AESR'], axis = 1, inplace = True)



# Normalizing the data

normalized_data = data.apply(lambda iterator: ((iterator - iterator.mean())/iterator.std()).round(2))

normalized_data.drop(['Crop_Yield'], axis = 1, inplace = True)

normalized_data.head()

def confidence_interval(actual, predicted, confidence):
  count = 0
  i = 0
  while i<len(actual):
    if predicted[i] <= (1 + confidence) * actual[i]  and predicted[i] >= (1 - confidence) * actual[i]:
      count+=1
    i+=1
  return count/len(actual) * 100



from sklearn.model_selection import train_test_split


# split the dataset
X_train, X_test, y_train, y_test = train_test_split(
    normalized_data, data['Crop_Yield'], test_size=0.25, random_state=0)

"""# **Polynomial Regression**"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
# define the pipeline and train model
poly_regression = Pipeline([('poly', PolynomialFeatures(degree=2)),
                  ('linear', LinearRegression(fit_intercept=False))])
                  
poly_regression.fit(X_train, y_train)

y_pred = poly_regression.predict(X_test)
# y_actual = list(test_label['Crop Yield'])
rms = mean_squared_error(y_test, y_pred, squared=False)

print("RMSE = ", rms)
ci1 = confidence_interval(list(y_test), list(y_pred), 0.05)
print("confidence = ",confidence_interval(list(y_test), list(y_pred), 0.05))
print("confidence = ",confidence_interval(list(y_test), list(y_pred), 0.10))



confidence = [ 0.05 , 0.10, 0.15, 0.20, 0.25]
confidence_score = dict()
for c in confidence:
  confidence_score[str(1 - c)] = (confidence_interval(list(y_test), list(y_pred), c))
courses = list(confidence_score.keys())
values = list(confidence_score.values())
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(courses, values)
 
plt.xlabel("Confidence Interval")
plt.ylabel("Confidence Scores")
plt.show()

# Calculating Correlation Coefficient

my_rho = np.corrcoef(np.array(y_test).flatten(), np.array(y_pred).flatten())
print("Correlation Coefficient = ", my_rho[0][1])

# Calculating R2 score
from sklearn.metrics import r2_score
print("R2 Score = ", r2_score(y_test, y_pred))

ci1 = confidence_interval(list(y_test), list(y_pred), 0.05)
ci2 = confidence_interval(list(y_test), list(y_pred), 0.10)
rmse.append(rms)
ci_95.append(ci1)
ci_90.append(ci2)
r2.append(r2_score(y_test, y_pred))
corr.append(my_rho[0][1])

"""# **Random Forest Regressor**"""

from sklearn.ensemble import RandomForestRegressor

 # create regressor object
regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)

# fit the regressor with x and y data
regressor.fit(X_train, y_train)

y_pred = regressor.predict(X_test)
# y_actual = list(test_label['Crop Yield'])
rms = mean_squared_error(y_test, y_pred, squared=False)
print("RMSE = ", rms)
print("confidence = ",confidence_interval(list(y_test), list(y_pred), 0.05))
print("confidence = ",confidence_interval(list(y_test), list(y_pred), 0.10))

confidence = [ 0.05 , 0.10, 0.15, 0.20, 0.25]
confidence_score = dict()
for c in confidence:
  confidence_score[str(1 - c)] = (confidence_interval(list(y_test), list(y_pred), c))
courses = list(confidence_score.keys())
values = list(confidence_score.values())
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(courses, values)
 
plt.xlabel("Confidence Interval")
plt.ylabel("Confidence Scores")
plt.show()

# Calculating Correlation Coefficient

my_rho = np.corrcoef(np.array(y_test).flatten(), np.array(y_pred).flatten())
print("Correlation Coefficient = ", my_rho[0][1])

# Calculating R2 score
from sklearn.metrics import r2_score
print("R2 Score = ", r2_score(y_test, y_pred))

ci1 = confidence_interval(list(y_test), list(y_pred), 0.05)
ci2 = confidence_interval(list(y_test), list(y_pred), 0.10)
rmse.append(rms)
ci_95.append(ci1)
ci_90.append(ci2)
r2.append(r2_score(y_test, y_pred))
corr.append(my_rho[0][1])

"""# **DNN**"""

checkpoint_path = "DL_model"
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,monitor = 'val_loss',save_best_only=True, save_weights_only=False,verbose=1)

model = Sequential()
model.add(Dense(16, kernel_initializer='normal', activation='relu'))
model.add(Dense(32, kernel_initializer='normal', activation='relu'))
model.add(Dense(16, kernel_initializer='normal', activation='relu'))
model.add(Dense(8, kernel_initializer='normal', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
# Compile model
model.compile(loss='mean_squared_error', optimizer='adam',metrics = ['mse' , 'mae'])

hist = model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1, validation_split=0.25, callbacks = [cp_callback])

train_loss = hist.history['loss']
index = range(len(train_loss))
val_loss = hist.history['val_loss']

plt.plot(index, train_loss, label = 'Training Loss')
plt.plot(index, val_loss, label = 'Validation Loss')
plt.legend()
plt.show()

model = keras.models.load_model('/content/DL_model')
y_pred = model.predict(X_test)
# y_actual = list(test_label['Crop Yield'])
rms = mean_squared_error(y_test, y_pred, squared=False)
print("RMSE = ", rms)
print("confidence = ",confidence_interval(list(y_test), list(y_pred), 0.05))
print("confidence = ",confidence_interval(list(y_test), list(y_pred), 0.10))

confidence = [ 0.05 , 0.10, 0.15, 0.20, 0.25]
confidence_score = dict()
for c in confidence:
  confidence_score[str(1 - c)] = (confidence_interval(list(y_test), list(y_pred), c))
courses = list(confidence_score.keys())
values = list(confidence_score.values())
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(courses, values)
 
plt.xlabel("Confidence Interval")
plt.ylabel("Confidence Scores")
plt.show()

# Calculating Correlation Coefficient

my_rho = np.corrcoef(np.array(y_test).flatten(), np.array(y_pred).flatten())
print("Correlation Coefficient = ", my_rho[0][1])

# Calculating R2 score
from sklearn.metrics import r2_score
print("R2 Score = ", r2_score(y_test, y_pred))

ci1 = confidence_interval(list(y_test), list(y_pred), 0.05)
ci2 = confidence_interval(list(y_test), list(y_pred), 0.10)
rmse.append(rms)
ci_95.append(ci1)
ci_90.append(ci2)
r2.append(r2_score(y_test, y_pred))
corr.append(my_rho[0][1])

"""## **CNN - DNN**"""

checkpoint_path = "CNN_DL_model"
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,monitor = 'val_loss',save_best_only=True, save_weights_only=False,verbose=1)

train_data = np.array(X_train)
train_data = train_data.reshape(train_data.shape[0], train_data.shape[1], 1).astype('float32')

train_data.shape

model = Sequential()
model.add(Conv1D(16, 1, activation='relu'))
model.add(Conv1D(32, 1, activation='relu'))
model.add(Conv1D(16, 1, activation='relu'))
model.add(Flatten())
model.add(Dense(32, kernel_initializer='normal', activation='relu'))
model.add(Dense(64, kernel_initializer='normal', activation='relu'))
model.add(Dense(16, kernel_initializer='normal', activation='relu'))
model.add(Dense(8, kernel_initializer='normal', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
# Compile model
model.compile(loss='mean_squared_error', optimizer='adam',metrics = ['mse' , 'mae'])

hist_cnn = model.fit(train_data, y_train, batch_size=64, epochs=100, verbose=1, validation_split=0.25, callbacks = [cp_callback])

train_loss = hist_cnn.history['loss']
index = range(len(train_loss))
val_loss = hist_cnn.history['val_loss']

plt.plot(index, train_loss, label = 'Training Loss')
plt.plot(index, val_loss, label = 'Validation Loss')
plt.legend()
plt.show()

model = keras.models.load_model('/content/CNN_DL_model')
y_pred = model.predict(X_test)
# y_actual = list(test_label['Crop Yield'])
rms = mean_squared_error(y_test, y_pred, squared=False)
print("RMSE = ", rms)
print("confidence = ",confidence_interval(list(y_test), list(y_pred), 0.05))
print("confidence = ",confidence_interval(list(y_test), list(y_pred), 0.10))

confidence = [ 0.05 , 0.10, 0.15, 0.20, 0.25]
confidence_score = dict()
for c in confidence:
  confidence_score[str(1 - c)] = (confidence_interval(list(y_test), list(y_pred), c))
courses = list(confidence_score.keys())
values = list(confidence_score.values())
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(courses, values)
 
plt.xlabel("Confidence Interval")
plt.ylabel("Confidence Scores")
plt.show()

# Calculating Correlation Coefficient

my_rho = np.corrcoef(np.array(y_test).flatten(), np.array(y_pred).flatten())
print("Correlation Coefficient = ", my_rho[0][1])

# Calculating R2 score
from sklearn.metrics import r2_score
print("R2 Score = ", r2_score(y_test, y_pred))

ci1 = confidence_interval(list(y_test), list(y_pred), 0.05)
ci2 = confidence_interval(list(y_test), list(y_pred), 0.10)
rmse.append(rms)
ci_95.append(ci1)
ci_90.append(ci2)
r2.append(r2_score(y_test, y_pred))
corr.append(my_rho[0][1])

"""# **LSTM Model**"""

normalized_data['Crop_Yield'] = data['Crop_Yield']

normalized_data.head()

lstm_data = []
lstm_target = []

lat = -1
lon = -1
n = 5

i = 0

while i < len(normalized_data):
  if normalized_data.iloc[i]['Latitude'] != lat or normalized_data.iloc[i]['Longitude'] != lon:
    lat = normalized_data.iloc[i]['Latitude']
    lon = normalized_data.iloc[i]['Longitude']
    i+=n
  else:
    temp = []
    lstm_target.append(normalized_data.iloc[i]['Crop_Yield'])
    for j in range(1,n+1):
      temp.insert(0,list(normalized_data.iloc[i - j]))
    lstm_data.append(temp)
    i+=1
    print(i)

train_data = np.array(lstm_data)
train_data.shape

train_label = np.array(lstm_target)
train_label.shape

from sklearn.model_selection import train_test_split
 
# split the dataset
X_train, X_test, y_train, y_test = train_test_split(
    train_data, train_label, test_size=0.25, random_state=0)

"""# **LSTM Model**"""

from keras.layers import Input, LSTM, Dense, Dropout
checkpoint_path = "LSTM_model"
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,monitor = 'val_loss',save_best_only=True, save_weights_only=False,verbose=1)

model = Sequential()
model.add(LSTM(32,return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[-1])))
model.add(Dropout(0.1))
# model.add(LSTM(32,return_sequences=True))
# model.add(Dropout(0.1))
# model.add(LSTM(16,return_sequences=True))
# model.add(Dropout(0.1))
model.add(LSTM(16,return_sequences=False))
model.add(Dropout(0.1))
model.add(Dense(16, kernel_initializer='normal', activation='relu'))
model.add(Dense(8, kernel_initializer='normal', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
# Compile model
model.compile(loss='mean_squared_error', optimizer='adam',metrics = ['mse' , 'mae'])

hist = model.fit(X_train, y_train, batch_size=64, epochs=100, verbose=1, validation_split=0.25, callbacks = [cp_callback])

train_loss = hist.history['loss']
index = range(len(train_loss))
val_loss = hist.history['val_loss']

plt.plot(index, train_loss, label = 'Training Loss')
plt.plot(index, val_loss, label = 'Validation Loss')
plt.legend()
plt.show()

lstm_model = keras.models.load_model('/content/LSTM_model')
y_pred = lstm_model.predict(X_test)
# y_actual = list(test_label['Crop Yield'])
rms = mean_squared_error(y_test, y_pred, squared=False)
print("RMSE = ", rms)
print("confidence = ",confidence_interval(list(y_test), list(y_pred), 0.05))
print("confidence = ",confidence_interval(list(y_test), list(y_pred), 0.10))

confidence = [ 0.05 , 0.10, 0.15, 0.20, 0.25]
confidence_score = dict()
for c in confidence:
  confidence_score[str(1 - c)] = (confidence_interval(list(y_test), list(y_pred), c))
courses = list(confidence_score.keys())
values = list(confidence_score.values())
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(courses, values)
 
plt.xlabel("Confidence Interval")
plt.ylabel("Confidence Scores")
plt.show()

# Calculating Correlation Coefficient

my_rho = np.corrcoef(np.array(y_test).flatten(), np.array(y_pred).flatten())
print("Correlation Coefficient = ", my_rho[0][1])

# Calculating R2 score
from sklearn.metrics import r2_score
print("R2 Score = ", r2_score(y_test, y_pred))

ci1 = confidence_interval(list(y_test), list(y_pred), 0.05)
ci2 = confidence_interval(list(y_test), list(y_pred), 0.10)
rmse.append(rms)
ci_95.append(ci1)
ci_90.append(ci2)
r2.append(r2_score(y_test, y_pred))
corr.append(my_rho[0][1])

results = pd.DataFrame(list(zip(rmse, ci_95, ci_90, r2, corr)), columns =['RMSE', '95 % Confidence Interval', '90 % Confidence Interval', 'R2 Score', 'Correlation Coefficient'])
results.to_csv("Results.csv", index = False)